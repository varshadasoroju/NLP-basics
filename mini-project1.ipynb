{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a Python NLTK program to split the text sentence/paragraph into a list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string:\n",
      "\n",
      "My name is Varsha.\n",
      "I currently study in IIITDM JABALPUR. \n",
      "I am pursuing my final year currently.\n",
      "\n",
      "Sentence-tokenized copy in a list:\n",
      "['\\nMy name is Varsha.', 'I currently study in IIITDM JABALPUR.', 'I am pursuing my final year currently.']\n",
      "Read the list:\n",
      "\n",
      "My name is Varsha.\n",
      "I currently study in IIITDM JABALPUR.\n",
      "I am pursuing my final year currently.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Varsha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "My name is Varsha.\n",
    "I currently study in IIITDM JABALPUR. \n",
    "I am pursuing my final year currently.\n",
    "'''\n",
    "print(\"Original string:\")\n",
    "print(text)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "token_text = sent_tokenize(text)\n",
    "print(\"Sentence-tokenized copy in a list:\")\n",
    "print(token_text)\n",
    "print(\"Read the list:\")\n",
    "for s in token_text:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a Python NLTK program to tokenize sentences in languages other than English. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string:\n",
      "\n",
      "NLTK ist Open Source Software. Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.  \n",
      "Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine \n",
      "abgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.\n",
      "\n",
      "Sentence-tokenized copy in a list:\n",
      "['\\nNLTK ist Open Source Software.', 'Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.', 'Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine \\nabgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.']\n",
      "Read the list:\n",
      "\n",
      "NLTK ist Open Source Software.\n",
      "Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.\n",
      "Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine \n",
      "abgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "NLTK ist Open Source Software. Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.  \n",
    "Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine \n",
    "abgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.\n",
    "'''\n",
    "print(\"Original string:\")\n",
    "print(text)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "token_text = sent_tokenize(text, language='german')\n",
    "print(\"Sentence-tokenized copy in a list:\")\n",
    "print(token_text)\n",
    "print(\"Read the list:\")\n",
    "for s in token_text:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a Python NLTK program to create a list of words from a given string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string:\n",
      "Joe waited for the train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station.\n",
      "List of words:\n",
      "['Joe', 'waited', 'for', 'the', 'train', '.', 'The', 'train', 'was', 'late', '.', 'Mary', 'and', 'Samantha', 'took', 'the', 'bus', '.', 'I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"Joe waited for the train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station.\"\n",
    "print(\"Original string:\")\n",
    "print(text)\n",
    "print(\"List of words:\")\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a Python NLTK program to split all punctuation into separate tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string:\n",
      "Reset your password if you just can't remember your old one.\n",
      "Split all punctuation into separate tokens:\n",
      "['Reset', 'your', 'password', 'if', 'you', 'just', 'can', \"'\", 't', 'remember', 'your', 'old', 'one', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "text = \"Reset your password if you just can't remember your old one.\"\n",
    "print(\"Original string:\")\n",
    "print(text)\n",
    "result = WordPunctTokenizer().tokenize(text)\n",
    "print(\"Split all punctuation into separate tokens:\")\n",
    "print(result) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
